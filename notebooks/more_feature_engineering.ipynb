{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "\n",
    "\n",
    "import tsfresh\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'searcher_results_orgenizer' from 'c:\\\\Users\\\\Bina4\\\\Desktop\\\\Guy_hafifa\\\\scrabble\\\\searcher_results_orgenizer.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "\n",
    "import board_helpers\n",
    "from board_helpers.move_info import MoveInfo\n",
    "from board_helpers.tiles_counter import TilesCounter\n",
    "from board_helpers.board_consts import TileType\n",
    "importlib.reload(board_helpers)\n",
    "importlib.reload(board_helpers.move_info)\n",
    "importlib.reload(board_helpers.tiles_counter)\n",
    "importlib.reload(board_helpers.board_consts)\n",
    "\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers.columns_setter_transformer import ColumnsSetterTransformer\n",
    "from transformers.extract_set_column_transformer import ExtractSetColumnsTransformer\n",
    "from transformers.name_dropper_transformer import NameDropperTransformer\n",
    "from transformers.select_transformer import SelectTransformer\n",
    "from transformers.select_by_index_transformer import SelectByIndexTransformer\n",
    "from transformers.series_from_group_transformer import SeriesFromGroupTransformer\n",
    "from transformers.map_set_transformer import MapSetTransformer\n",
    "from transformers.one_hot_encoder_transformer import OneHotEncoderTransformer\n",
    "from transformers.add_to_dict_transformer import AddToDictTransformer\n",
    "from transformers.get_from_dict_transformer import GetFromDictTransformer\n",
    "from transformers.select_by_mask_transformer import SelectByMaskTransformer\n",
    "from transformers.select_features_wrapper import SelectFeaturesWrapper\n",
    "from transformers.my_turns_transformation import MyTurnsTransformation\n",
    "from transformers.turns_transformer import TurnsTransformer\n",
    "importlib.reload(transformers)\n",
    "importlib.reload(transformers.columns_setter_transformer)\n",
    "importlib.reload(transformers.extract_set_column_transformer)\n",
    "importlib.reload(transformers.name_dropper_transformer)\n",
    "importlib.reload(transformers.select_transformer)\n",
    "importlib.reload(transformers.select_by_index_transformer)\n",
    "importlib.reload(transformers.series_from_group_transformer)\n",
    "importlib.reload(transformers.map_set_transformer)\n",
    "importlib.reload(transformers.one_hot_encoder_transformer)\n",
    "importlib.reload(transformers.add_to_dict_transformer)\n",
    "importlib.reload(transformers.get_from_dict_transformer)\n",
    "importlib.reload(transformers.select_by_mask_transformer)\n",
    "importlib.reload(transformers.select_features_wrapper)\n",
    "importlib.reload(transformers.my_turns_transformation)\n",
    "importlib.reload(transformers.turns_transformer)\n",
    "\n",
    "\n",
    "import functions\n",
    "from functions.bot_extractor import BotExtarctor\n",
    "from functions.is_bot_extractor import IsBotExtarctor\n",
    "importlib.reload(functions)\n",
    "importlib.reload(functions.is_bot_extractor)\n",
    "importlib.reload(functions.bot_extractor)\n",
    "\n",
    "import processors\n",
    "from processors.basic_pre_processor import BasicPreProcessor\n",
    "importlib.reload(processors)\n",
    "importlib.reload(processors.basic_pre_processor)\n",
    "\n",
    "import builders\n",
    "from builders.preprocessor_builder import PreprocessorBuilder\n",
    "from builders.reg_pipe_builder import RegPipeBuilder\n",
    "importlib.reload(builders)\n",
    "importlib.reload(builders.preprocessor_builder)\n",
    "importlib.reload(builders.reg_pipe_builder)\n",
    "\n",
    "import searcher\n",
    "import searcher_results_orgenizer\n",
    "from searcher import Searcher\n",
    "from searcher_results_orgenizer import SearcherResultsOrgenizer\n",
    "importlib.reload(searcher)\n",
    "importlib.reload(searcher_results_orgenizer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv('../data/games.csv', index_col='game_id')\n",
    "train = pd.read_csv('../data/train.csv', index_col='game_id')\n",
    "turns = pd.read_csv('../data/turns.csv', index_col='game_id')\n",
    "fs_turns = pd.read_csv('../data/fs_turns.csv', index_col='game_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_NAME = 'games'\n",
    "T_NAME = 'turns'\n",
    "DATA_NAME = 'train'\n",
    "\n",
    "names = ['BetterBot', 'STEEBot', 'HastyBot']\n",
    "\n",
    "features = np.load('../feature_selection_consts/columns.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "prePipe = Pipeline([\n",
    "                    ('get_relavent_turns', SelectByIndexTransformer(train.index.unique(), target=T_NAME)),\n",
    "                     ('get_relavent_games',  SelectByIndexTransformer(train.index.unique(), target=G_NAME)),\n",
    "                     ('train_set_is_player', ExtractSetColumnsTransformer({'is_player': IsBotExtarctor(names, 'nickname', True)},\n",
    "                                                                           src=DATA_NAME, dest=DATA_NAME)),\n",
    "                     ('get_bot_rating', ExtractSetColumnsTransformer({'bot_rating': lambda train: train[~train['is_player']]['rating']},\n",
    "                                                                      src=DATA_NAME, dest=G_NAME)),\n",
    "                     ('get_bots_names', ExtractSetColumnsTransformer({'bot_name': lambda train: train[~train['is_player']]['nickname']},\n",
    "                                                                     src=DATA_NAME, dest=G_NAME)),\n",
    "                    ('data_drop_bot_rating', SelectByMaskTransformer('is_player', target=DATA_NAME)),\n",
    "                    ])\n",
    "preprocessor = PreprocessorBuilder(games, G_NAME, turns, T_NAME, prePipe).build()\n",
    "n_games, n_turns, n_ratings = preprocessor.process(train, DATA_NAME)\n",
    "# t_turns = MyTurnsTransformation().transform(n_turns) # I want to add that to pre later\n",
    "# n_data = n_games.merge(t_turns, left_index=True, right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['Z', 'A', 'I', '.', 'e', 'l']\n",
    "names = ['BetterBot', 'STEEBot', 'HastyBot']\n",
    "\n",
    "initial_pipe = Pipeline([\n",
    "                ('hot', OneHotEncoderTransformer({'turn_type': turns['turn_type'].unique()})),\n",
    "                ('count_letters_used',\n",
    "                MapSetTransformer({letter: (lambda x, letter=letter: x.count(letter) if type(x) == str else 0, 'move') for letter in letters})),\n",
    "                ('count_tiles_used', \n",
    "                ExtractSetColumnsTransformer(\n",
    "                    {str(t_type): (lambda turns, t_type=t_type: \n",
    "                                   turns.apply(lambda x: \n",
    "                                               TilesCounter(x['location'], x['move'])()[t_type] if type(x['location'])==str and type(x['move'])==str else 0, axis=1))\n",
    "                     \n",
    "                     for t_type in TileType}\n",
    "                )),\n",
    "                ('special_tiles', \n",
    "                ExtractSetColumnsTransformer(\n",
    "                    {'special_type': (lambda turns: turns.apply(lambda x: x['TileType.L2'] + x['TileType.L3'] + x['TileType.W2'] + x['TileType.W3'], axis=1))}\n",
    "                )),\n",
    "                ('turns_word_info_mappers', MapSetTransformer({'move_len': (lambda x: len(x) if type(x) == str else 0, 'move'), \n",
    "                                                               'jokers_num': (lambda x: \n",
    "                                                                              sum(1 for c in x if c.islower()) if (type(x) == str) and (x not in ['(challenge)', '(time)']) else 0, 'move'),\n",
    "                                                }),),\n",
    "                ('set_is_player', ExtractSetColumnsTransformer({'is_player': IsBotExtarctor(names, 'nickname', True)},)), \n",
    "                # ('bool_to_int', ExtractSetColumnsTransformer({'is_player': lambda turns: turns['is_player'].astype(int)})),\n",
    "                ('drops', NameDropperTransformer(['turn_type', 'nickname', 'move', 'location', 'rack'])),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a_turn_type_Challenge__mean', 'a_turn_type_Pass__sum_values',\n",
       "       'a_turn_type_Timeout__mean', 'a_Z__mean', 'p_points__sum_values',\n",
       "       'p_points__median', 'p_points__mean', 'p_points__root_mean_square',\n",
       "       'p_score__root_mean_square', 'p_score__maximum',\n",
       "       'p_turn_type_End__mean', 'p_turn_type_Exchange__sum_values',\n",
       "       'p_turn_type_Pass__mean', 'p_turn_type_Pass__standard_deviation',\n",
       "       'p_turn_type_Play__mean', 'p_A__maximum', 'p_I__maximum', 'p_.__median',\n",
       "       'p_move_len__mean', 'p_move_len__root_mean_square',\n",
       "       'p_jokers_num__sum_values', 'p_jokers_num__mean',\n",
       "       'b_turn_type_End__mean', 'b_e__standard_deviation', 'b_l__mean',\n",
       "       'b_move_len__sum_values', 'b_jokers_num__mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_turns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_mean_std_col = ['points', 'turn_type_Challenge',\n",
    "       'turn_type_End', 'turn_type_Exchange', 'turn_type_Pass',\n",
    "       'turn_type_Play', 'turn_type_Six-Zero Rule', 'turn_type_Timeout',\n",
    "       '.','TileType.N',\n",
    "       'TileType.L2', 'TileType.L3', 'TileType.W2', 'TileType.W3',\n",
    "       'special_type', 'move_len', 'jokers_num']\n",
    "\n",
    "to_max_col = ['points', '.',  'TileType.N',\n",
    "       'TileType.L2', 'TileType.L3', 'TileType.W2', 'TileType.W3',\n",
    "       'special_type', 'move_len', 'jokers_num'\n",
    "]\n",
    "\n",
    "to_sum_col = ['turn_type_Challenge',\n",
    "        'turn_type_Exchange', 'turn_type_Pass',\n",
    "       'turn_type_Play', 'turn_type_Six-Zero Rule', 'turn_type_Timeout',\n",
    "        '.', 'TileType.N',\n",
    "       'TileType.L2', 'TileType.L3', 'TileType.W2', 'TileType.W3',\n",
    "       'special_type', 'move_len', 'jokers_num']\n",
    "\n",
    "types = ['TileType.N', 'TileType.L2', 'TileType.L3', 'TileType.W2', 'TileType.W3', 'special_type']\n",
    "mapings = {\n",
    "             'p_point_dec_weighted_mean': lambda turns: \n",
    "                                          turns[turns['is_player']].apply(lambda x: x['points']/x['turn_number'], axis=1).groupby('game_id').mean(),\n",
    "             'p_point_inc_weighted_mean': lambda turns:\n",
    "                                          turns[turns['is_player']].apply(lambda x: x['points'] * np.log(x['turn_number']), axis=1).groupby('game_id').mean(),\n",
    "             'p_points_by_len_sum': lambda turns: (turns['points']/turns['move_len']).replace([np.inf, -np.inf], np.nan)[turns['is_player']].groupby('game_id').sum(),\n",
    "              'p_points_by_len_mean': lambda turns: (turns['points']/turns['move_len']).replace([np.inf, -np.inf], np.nan)[turns['is_player']].groupby('game_id').mean(),\n",
    "\n",
    "          }\n",
    "mapings.update({f'p_{name}__mean': lambda turns, name=name: turns[turns['is_player']][name].groupby('game_id').mean()\n",
    "                for name in types})\n",
    "mapings.update({f'p_{name}__std': lambda turns, name=name: turns[turns['is_player']][name].groupby('game_id').std()\n",
    "                for name in types})\n",
    "mapings.update({f'p_{name}__mean': lambda turns, name=name: turns[turns['is_player']][name].groupby('game_id').max()\n",
    "                for name in types})\n",
    "mapings.update({f'p_{name}__sum': lambda turns, name=name: turns[turns['is_player']][name].groupby('game_id').sum()\n",
    "                for name in types})\n",
    "mapings.update({f'b_{name}__mean': lambda turns, name=name: turns[~turns['is_player']][name].groupby('game_id').mean()\n",
    "                for name in types})\n",
    "mapings.update({f'a_{name}__mean': lambda turns, name=name: turns[name].groupby('game_id').mean()\n",
    "                for name in types})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_t_turns = pd.read_csv('../data/my_t_turns.csv', index_col='game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns_transformer = TurnsTransformer(\n",
    "                                        # initial_pipe=initial_pipe, \n",
    "                                        mappers=mapings\n",
    "                                    )\n",
    "t_turns = turns_transformer.transform(i_t_turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = n_games.merge(t_turns, left_index=True, right_index=True).merge(fs_turns, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureTransformers = [('extract_first', ColumnsSetterTransformer({'is_bot_first': IsBotExtarctor(names, name_col='first')})),\n",
    "                       ('hot', OneHotEncoderTransformer({'time_control_name': games['time_control_name'].unique(),\n",
    "                                                          'game_end_reason':  games['game_end_reason'].unique(),\n",
    "                                                          'lexicon':  games['lexicon'].unique(),\n",
    "                                                          'rating_mode':  games['rating_mode'].unique(),\n",
    "                                                          'bot_name': names}\n",
    "                                                        )),\n",
    "                       ('select_col', SelectTransformer(features)),\n",
    "                      #  ('dropper', NameDropperTransformer(\n",
    "                      #               [\n",
    "                      #               # 'first', 'time_control_name', 'game_end_reason', 'created_at',\n",
    "                      #               # 'lexicon', 'rating_mode','bot_name',\n",
    "                      #               # 'time_control_name_nan','game_end_reason_nan' ,'lexicon_nan', 'rating_mode_nan', 'bot_name_nan',\n",
    "                      #               'bot_rating'\n",
    "                      #               ])),\n",
    "                       # add regressor                                              \n",
    "                      ]\n",
    "\n",
    "reg_pipe = Pipeline(featureTransformers)\n",
    "trans = reg_pipe.transform(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.17320508075688773,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.17320508075688773,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, gamma=0, gpu_id=None,\n",
       "             grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.17320508075688773,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=0, ...)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = XGBRegressor(random_state=0,\n",
    "                    max_depth=7, min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=1, colsample_bytree=1,\n",
    "                    reg_alpha=0.00005, reg_lambda=1,\n",
    "                    learning_rate=np.sqrt(3)/10\n",
    "                    )\n",
    "reg.fit(trans, n_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = cross_validate(reg, trans, n_ratings, cv=5,\n",
    "                         scoring=('neg_root_mean_squared_error'),\n",
    "                         return_train_score=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time         4.830136\n",
       "score_time       0.021596\n",
       "test_score    -105.045024\n",
       "train_score    -85.112928\n",
       "dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_res).mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
